{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy and pandas libraries \n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read iris flower data set and assign it to pandas dataframe\n",
    "df_iris = pd.read_csv('https://raw.githubusercontent.com/mpourhoma/CS4661/master/iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width\n",
       "0             5.1          3.5           1.4          0.2\n",
       "10            5.4          3.7           1.5          0.2\n",
       "20            5.4          3.4           1.7          0.2\n",
       "30            4.8          3.1           1.6          0.2\n",
       "40            5.0          3.5           1.3          0.3\n",
       "50            7.0          3.2           4.7          1.4\n",
       "60            5.0          2.0           3.5          1.0\n",
       "70            5.9          3.2           4.8          1.8\n",
       "80            5.5          2.4           3.8          1.1\n",
       "90            5.5          2.6           4.4          1.2\n",
       "100           6.3          3.3           6.0          2.5\n",
       "110           6.5          3.2           5.1          2.0\n",
       "120           6.9          3.2           5.7          2.3\n",
       "130           7.4          2.8           6.1          1.9\n",
       "140           6.7          3.1           5.6          2.4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create feature matrix for iris dataset:\n",
    "#this creates a list of feature names in the dataset\n",
    "feature_cols = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "#select features from the DataFrame\n",
    "X = df_iris[feature_cols]\n",
    "\n",
    "#printing list of features for checking purposes\n",
    "X[::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          setosa\n",
       "10         setosa\n",
       "20         setosa\n",
       "30         setosa\n",
       "40         setosa\n",
       "50     versicolor\n",
       "60     versicolor\n",
       "70     versicolor\n",
       "80     versicolor\n",
       "90     versicolor\n",
       "100     virginica\n",
       "110     virginica\n",
       "120     virginica\n",
       "130     virginica\n",
       "140     virginica\n",
       "Name: species, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#selects labels from DataFrame and set in y variable\n",
    "y = df_iris['species']\n",
    "\n",
    "#print list of labels for checking purposes\n",
    "y[::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import train_test_split library\n",
    "#split data into training (60%) and testing set (40%)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4,random_state = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate object of KNeighborsClassifier with k = 3\n",
    "k = 3\n",
    "knn_kevin = KNeighborsClassifier(n_neighbors = k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model on training set\n",
    "knn_kevin.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'virginica' 'setosa' 'setosa' 'virginica' 'versicolor'\n",
      " 'virginica' 'setosa' 'virginica' 'versicolor' 'virginica' 'versicolor'\n",
      " 'virginica' 'virginica' 'versicolor' 'versicolor' 'virginica'\n",
      " 'versicolor' 'versicolor' 'setosa' 'setosa' 'virginica' 'setosa' 'setosa'\n",
      " 'versicolor' 'versicolor' 'versicolor' 'virginica' 'setosa' 'versicolor'\n",
      " 'setosa' 'versicolor' 'setosa' 'setosa' 'versicolor' 'virginica'\n",
      " 'versicolor' 'virginica' 'versicolor' 'setosa' 'setosa' 'virginica'\n",
      " 'versicolor' 'versicolor' 'setosa' 'setosa' 'versicolor' 'setosa'\n",
      " 'setosa' 'versicolor' 'virginica' 'virginica' 'virginica' 'setosa'\n",
      " 'virginica' 'setosa' 'setosa' 'setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "#test model on testing set\n",
    "y_predict = knn_kevin.predict(X_test)\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "#import accuracy score and find accuracy percentage\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test,y_predict)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95, 0.9833333333333333, 0.9666666666666667, 0.9666666666666667, 0.9333333333333333, 0.9166666666666666, 0.8166666666666667]\n"
     ]
    }
   ],
   "source": [
    "#save K values into a list\n",
    "list = [1, 5, 7, 11, 15, 27, 59]\n",
    "#create empty list to save accuracy values in\n",
    "acc = []\n",
    "#create forloop to iterate through list and find accuracy based on \"K\" values in list\n",
    "\n",
    "for l in list:\n",
    "    #set n_neighbors to values in list\n",
    "    knn_kevin = KNeighborsClassifier(n_neighbors=l)\n",
    "    #train data on training set\n",
    "    knn_kevin.fit(X_train, y_train)\n",
    "    #test data on testing set\n",
    "    y_predict = knn_kevin.predict(X_test)\n",
    "    #find accuracy of testing set vs actual lavels\n",
    "    accuracy = accuracy_score(y_test, y_predict)\n",
    "    #save the accuracy values into empty list \"acc\"\n",
    "    acc.append(accuracy)\n",
    "    \n",
    "print(acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the accuracy always get better by increasing the value of K?\n",
    "\n",
    "After k = 5 the accuracy of the predictions decreases so when K increases greatly the accuracy percentage decreases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new feature columns based on each of 4 features\n",
    "#sepal_length\n",
    "feature_col1 = ['sepal_length']\n",
    "X1 = df_iris[feature_col1]\n",
    "#sepal_width\n",
    "feature_col2 = ['sepal_width']\n",
    "X2 = df_iris[feature_col2]\n",
    "#petal_length\n",
    "feature_col3 = ['petal_length']\n",
    "X3 = df_iris[feature_col3]\n",
    "#petal_width\n",
    "feature_col4 = ['petal_width']\n",
    "X4 = df_iris[feature_col4]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data on feature_col1, sepal_length\n",
    "X1_train, X1_test, y_train, y_test = train_test_split(X1, y, test_size = 0.4,random_state = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data on feature_col2, sepal_width\n",
    "X2_train, X2_test, y_train, y_test = train_test_split(X2, y, test_size = 0.4,random_state = 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data on feature_col3, petal_length\n",
    "X3_train, X3_test, y_train, y_test = train_test_split(X3, y, test_size = 0.4,random_state = 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data on feature_col4, petal_width\n",
    "X4_train, X4_test, y_train, y_test = train_test_split(X4, y, test_size = 0.4,random_state = 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate object of KNeighborsClassifier with k = 3\n",
    "k = 3\n",
    "knn_kevin1 = KNeighborsClassifier(n_neighbors = k)\n",
    "knn_kevin2 = KNeighborsClassifier(n_neighbors = k)\n",
    "knn_kevin3 = KNeighborsClassifier(n_neighbors = k)\n",
    "knn_kevin4 = KNeighborsClassifier(n_neighbors = k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model on training set for each feature_col\n",
    "#sepal_length\n",
    "knn_kevin1.fit(X1_train, y_train)\n",
    "#sepal_width\n",
    "knn_kevin2.fit(X2_train, y_train)\n",
    "#petal_length\n",
    "knn_kevin3.fit(X3_train, y_train)\n",
    "#petal_width\n",
    "knn_kevin4.fit(X4_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test model on testing set for each feature_col\n",
    "#sepal_length\n",
    "y_predict1 = knn_kevin1.predict(X1_test)\n",
    "#sepal_width\n",
    "y_predict2 = knn_kevin2.predict(X2_test)\n",
    "#petal_length\n",
    "y_predict3 = knn_kevin3.predict(X3_test)\n",
    "#petal_width\n",
    "y_predict4 = knn_kevin4.predict(X4_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7166666666666667, 0.5666666666666667, 0.9333333333333333, 0.95]\n"
     ]
    }
   ],
   "source": [
    "#find accuracy percentage of each feature individually\n",
    "#create empty list to store accuracy values\n",
    "accList = []\n",
    "#accuracy of sepal_length\n",
    "accuracy1 = accuracy_score(y_test,y_predict1)\n",
    "accList.append(accuracy1)\n",
    "\n",
    "#accuracy of sepal_width\n",
    "accuracy2 = accuracy_score(y_test,y_predict2)\n",
    "accList.append(accuracy2)\n",
    "\n",
    "#accuracy of petal_length\n",
    "accuracy3 = accuracy_score(y_test,y_predict3)\n",
    "accList.append(accuracy3)\n",
    "\n",
    "#accuracy of petal_width\n",
    "accuracy4 = accuracy_score(y_test,y_predict4)\n",
    "accList.append(accuracy4)\n",
    "\n",
    "print(accList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which individual provides the best accuracy (the best feature)? \n",
    "\n",
    "Feature 4 -> petal_width\n",
    "\n",
    "Which one is the second best feature?\n",
    "\n",
    "Feature 3 -> petal_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new feature columns based on 2 of 4 features\n",
    "\n",
    "#sepal_length and sepal_width (features 1 and 2)\n",
    "feature_col12 = ['sepal_length', 'sepal_width']\n",
    "X12 = df_iris[feature_col12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sepal_length and petal_length (features 1 and 3)\n",
    "feature_col13 = ['sepal_length', 'petal_length']\n",
    "X13 = df_iris[feature_col13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sepal_length and petal_width (features 1 and 4)\n",
    "feature_col14 = ['sepal_length' , 'petal_width']\n",
    "X14 = df_iris[feature_col14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sepal_width and petal_length (features 2 and 3)\n",
    "feature_col23 = ['sepal_width' , 'petal_length']\n",
    "X23 = df_iris[feature_col23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sepal_width and petal_width (features 2 and 4)\n",
    "feature_col24 = ['sepal_width' , 'petal_width']\n",
    "X24 = df_iris[feature_col24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#petal_length and petal_width (features 3 and 4)\n",
    "feature_col34 = ['petal_length' , 'petal_width']\n",
    "X34 = df_iris[feature_col34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data on feature_col12, sepal_length and sepal_width\n",
    "X12_train, X12_test, y_train, y_test = train_test_split(X12, y, test_size = 0.4,random_state = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data on feature_col13, sepal_length and petal_length\n",
    "X13_train, X13_test, y_train, y_test = train_test_split(X13, y, test_size = 0.4,random_state = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data on feature_col14, sepal_length and petal_width\n",
    "X14_train, X14_test, y_train, y_test = train_test_split(X14, y, test_size = 0.4,random_state = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data on feature_col23, sepal_width and petal_length\n",
    "X23_train, X23_test, y_train, y_test = train_test_split(X23, y, test_size = 0.4,random_state = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data on feature_col24, sepal_width and petal_width\n",
    "X24_train, X24_test, y_train, y_test = train_test_split(X24, y, test_size = 0.4,random_state = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data on feature_col34, petal_length and petal_width\n",
    "X34_train, X34_test, y_train, y_test = train_test_split(X34, y, test_size = 0.4,random_state = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate object of KNeighborsClassifier with k = 3\n",
    "k = 3\n",
    "knn_kevin12 = KNeighborsClassifier(n_neighbors = k)\n",
    "knn_kevin13 = KNeighborsClassifier(n_neighbors = k)\n",
    "knn_kevin14 = KNeighborsClassifier(n_neighbors = k)\n",
    "knn_kevin23 = KNeighborsClassifier(n_neighbors = k)\n",
    "knn_kevin24 = KNeighborsClassifier(n_neighbors = k)\n",
    "knn_kevin34 = KNeighborsClassifier(n_neighbors = k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model on training set for each feature_col pair\n",
    "#sepal_length12\n",
    "knn_kevin12.fit(X12_train, y_train)\n",
    "\n",
    "#sepal_width13\n",
    "knn_kevin13.fit(X13_train, y_train)\n",
    "\n",
    "#petal_length14\n",
    "knn_kevin14.fit(X14_train, y_train)\n",
    "\n",
    "#petal_width23\n",
    "knn_kevin23.fit(X23_train, y_train)\n",
    "\n",
    "#petal_width24\n",
    "knn_kevin24.fit(X24_train, y_train)\n",
    "\n",
    "#petal_width34\n",
    "knn_kevin34.fit(X34_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test model on testing set for each feature_col pair\n",
    "\n",
    "#sepal_length and sepal_width\n",
    "y_predict12 = knn_kevin12.predict(X12_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sepal_length and petal_length\n",
    "y_predict13 = knn_kevin13.predict(X13_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sepal_length and petal_width\n",
    "y_predict14 = knn_kevin14.predict(X14_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sepal_width and petal_length\n",
    "y_predict23 = knn_kevin23.predict(X23_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sepal_width and petal_width\n",
    "y_predict24 = knn_kevin24.predict(X24_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#petal_length and petal_width\n",
    "y_predict34 = knn_kevin34.predict(X34_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find accuracy percentage of each feature pair\n",
    "#create empty list to store accuracy values\n",
    "featList = []\n",
    "\n",
    "#accuracy of sepal_length and sepal_width\n",
    "accuracy12 = accuracy_score(y_test,y_predict12)\n",
    "featList.append(accuracy12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy of sepal_length and petal_length\n",
    "accuracy13 = accuracy_score(y_test,y_predict13)\n",
    "featList.append(accuracy13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy of sepal_length and petal_width\n",
    "accuracy14 = accuracy_score(y_test,y_predict14)\n",
    "featList.append(accuracy14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy of sepal_width and petal_length\n",
    "accuracy23 = accuracy_score(y_test,y_predict23)\n",
    "featList.append(accuracy23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy of sepal_width and petal_width\n",
    "accuracy24 = accuracy_score(y_test,y_predict24)\n",
    "featList.append(accuracy24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy of petal_length and petal_width\n",
    "accuracy34 = accuracy_score(y_test,y_predict34)\n",
    "featList.append(accuracy34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8166666666666667, 0.9833333333333333, 0.95, 0.95, 0.95, 0.9666666666666667]\n"
     ]
    }
   ],
   "source": [
    "#print list of percentage accuracies\n",
    "print(featList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which feature pair provides the best accuracy?\n",
    "Features one (sepal_length) and feature three (petal_length) at a 98.333%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best feature pair from F contains feature one, which is sepal_length, and feature 3, which is petal_length at a 98.333%. In part E, the two best features were feature 4, sepal_width at 95% and feature 3, sepal_length at 93.333%. From this specific example we can conclude that the two best single features are not the best feature pair because the best feature pair, features 1 and 3, yielded a 98% accuracy while features 3 and 4, which are the best single features, yielded a 96.6% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I stated above, the best feature pair yielded a 98% accuracy rate while the two best single feautres paired together yielded a 96.6% accuracy rate. Even tho that is a tiny 1.4% difference, 2 other features yeilded a higher rate than the 2 single best, thus elimintaing the ability for the two best single features to have be the best feature pair. There might be error in my code somewhere but from the results shown above my analysis on the situation is correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
